# 🚀 机器学习快速开始指南

**更新日期**: 2025年1月29日
**适用版本**: 最新版本（包含export_data.sh脚本）指南

## 🎯 目标

使用机器学习预测用户输入的密码序列

## 📦 已创建的文件

```
ml_code/
├── 1_data_preprocessing.py      ✅ 数据预处理
├── 2_feature_extraction.py      ✅ 特征提取
├── 3_train_model.py             ✅ 模型训练
├── 4_predict_password.py        ✅ 密码预测
├── run_all.py                   ✅ 一键运行
├── README.md                    ✅ 详细文档
└── 快速开始.md                   ✅ 本文件
```

## ⚡ 3 分钟快速开始

### 第 1 步：安装依赖（1 分钟）

```bash
pip install pandas numpy scikit-learn scipy matplotlib seaborn joblib
```

### 第 2 步：导出数据（1 分钟）

```bash
# 回到项目根目录
cd /Users/east/AndroidStudioProjects/iotproject

# 使用脚本导出数据（推荐）
./export_data.sh

# 或手动导出
# adb -s RFCXA1767LX pull /sdcard/Android/data/com.example.iotproject/files/ ./sensor_data/
```

### 第 3 步：运行模型（1 分钟）

```bash
cd ml_code
python run_all.py --model random_forest
# 注意：现在默认路径是 ../sensor_data/files，不需要指定
```

**完成！** 🎉

---

## 📊 使用的算法

### 1. Random Forest（随机森林）- 默认推荐

**原理**：
- 建立 100 棵决策树
- 每棵树用不同的数据子集训练
- 预测时让所有树投票，多数获胜

**为什么好**：
- ✅ 准确率高（通常 60-75%）
- ✅ 不容易过拟合
- ✅ 可以看哪些特征最重要
- ✅ 训练快

**超参数**：
```python
n_estimators=100      # 100 棵树
max_depth=20          # 每棵树最大深度 20
min_samples_split=5   # 至少 5 个样本才分裂
```

### 2. XGBoost（梯度提升树）- 最高准确率

**原理**：
- 一棵一棵地建树
- 每棵新树专门修正前面树的错误
- 像团队合作，后面的人补前面人的不足

**为什么好**：
- ✅ 准确率最高（通常 65-80%）
- ✅ 效果通常比 Random Forest 好 5-10%

**缺点**：
- ❌ 需要额外安装：`pip install xgboost`
- ❌ 训练稍慢

### 3. SVM（支持向量机）

**原理**：
- 在高维空间找一个最优分界面
- 把不同数字分开

**适用场景**：
- 数据量小（< 500 个样本）

### 4. Logistic Regression（逻辑回归）

**原理**：
- 最简单的线性分类器

**适用场景**：
- 快速测试
- 基线模型

---

## 🔍 详细流程说明

### 步骤 1: 数据预处理

**做什么**：
1. 读取所有 `password_training_*.csv` 文件
2. 按 `label` 列分割（label 变化 = 新按键）
3. 每个按键保存为独立文件

**输入**：
```
../sensor_data/files/password_training_123456.csv
../sensor_data/files/password_training_123457.csv
...
```

**输出**：
```
processed_data/keypress_0000_label_5.csv  ← 第1次按键（数字5）
processed_data/keypress_0001_label_3.csv  ← 第2次按键（数字3）
...
processed_data/label_statistics.csv       ← 统计信息
```

### 步骤 2: 特征提取

**做什么**：
从每次按键的传感器数据中提取 200+ 个特征

**提取的特征**：

| 特征类型 | 示例 | 数量 |
|---------|------|------|
| 时域统计 | 均值、标准差、最大值、最小值 | ~120 |
| 频域特征 | FFT 能量、主频率、频谱质心 | ~80 |
| 总计 | | ~200 |

**为什么需要这么多特征**？
- 加速度计有 x, y, z 三轴，每轴 17 个特征 = 51 个
- 陀螺仪同理 = 51 个
- 旋转矢量有 x, y, z, w 四轴 = 68 个
- 磁力计三轴 = 51 个
- **总计约 200+ 个特征**

**输出**：
```
features.csv  ← 特征矩阵
```

CSV 格式：
```
ACC_x_mean,ACC_x_std,...,GYRO_x_mean,...,label
0.123,0.456,...,0.789,...,5
0.234,0.567,...,0.890,...,3
...
```

### 步骤 3: 训练模型

**做什么**：
1. 加载特征数据
2. 划分训练集（80%）和测试集（20%）
3. 训练分类器
4. 评估性能

**过程**：
```
特征矩阵 → 标准化 → 训练算法 → 保存模型
```

**评估指标**：
- **准确率**：整体预测正确的比例
- **混淆矩阵**：哪些数字容易混淆
- **特征重要性**：哪些传感器/特征最有用

**输出**：
```
models/random_forest_20250115_123456.pkl  ← 训练好的模型
confusion_matrix_random_forest.png        ← 混淆矩阵图
feature_importance_random_forest.png      ← 特征重要性
```

### 步骤 4: 预测密码

**做什么**：
1. 加载训练好的模型
2. 读取新的密码数据
3. 提取特征
4. 预测每个数字
5. 组合成完整密码

**示例**：
```bash
# 假设实际密码是 54321
python 4_predict_password.py \
    --model ./models/random_forest_xxx.pkl \
    --data ./new_password.csv \
    --actual 54321

# 输出：
# 按键 1: 预测=5, 实际=5, 置信度=85% ✓
# 按键 2: 预测=4, 实际=4, 置信度=72% ✓
# 按键 3: 预测=3, 实际=3, 置信度=91% ✓
# 按键 4: 预测=2, 实际=2, 置信度=68% ✓
# 按键 5: 预测=1, 实际=1, 置信度=79% ✓
#
# 预测的密码序列: 54321
# ✓ 完全正确！
```

---

## 🎓 实验建议

### 实验 1：基线测试（需要 100 个样本）

**目标**：看看模型能达到多少准确率

```bash
# 收集数据：每个数字按 10 次
# 运行模型
python run_all.py --model random_forest
```

**预期结果**：30-40% 准确率

### 实验 2：增加数据量（需要 500 个样本）

**目标**：验证数据量对准确率的影响

```bash
# 收集更多数据：每个数字按 50 次
# 重新训练
python run_all.py --model random_forest
```

**预期结果**：50-65% 准确率

### 实验 3：对比算法（需要 500+ 个样本）

**目标**：找到最佳算法

```bash
# 分别训练四种算法
python run_all.py --model random_forest
python run_all.py --model xgboost
python run_all.py --model svm
python run_all.py --model logistic
```

**对比**：哪个准确率最高？

### 实验 4：跨用户测试（可选）

**目标**：测试模型泛化能力

1. 用你的数据训练模型
2. 让朋友输入密码
3. 看看能否预测朋友的密码

**意义**：如果能预测，说明隐私风险更大！

---

## 📈 如何提高准确率？

### 1. 收集更多数据 ⭐⭐⭐⭐⭐

**最重要！**

| 样本数 | 准确率 |
|--------|--------|
| 100    | 30-40% |
| 500    | 50-65% |
| 1000   | 60-75% |
| 2000   | 70-85% |

### 2. 提高数据质量 ⭐⭐⭐⭐

- ✅ 按键自然、稳定
- ✅ 持握方式一致
- ✅ 避免太快或太慢

### 3. 尝试不同算法 ⭐⭐⭐

- XGBoost 通常比 Random Forest 好 5-10%

### 4. 调整超参数 ⭐⭐

修改 `3_train_model.py` 中的参数

---

## ❓ 常见问题

### Q1: 提示 "没有找到有效数据"

**原因**：CSV 文件中没有 label 列或 label 全部为空

**解决**：
1. 检查你是否用了"密码预测模式"收集数据
2. 确保按了数字键（会自动标注 label）
3. 注意：第一个按键的前500ms数据label为空是正常的，预处理脚本会自动过滤

### Q2: 准确率只有 10% 左右（随机猜测水平）

**原因**：数据量太少或质量太差

**解决**：
1. 至少收集 100 个样本
2. 每个数字至少 10 次

### Q3: 提示缺少某个 Python 包

**解决**：
```bash
pip install <包名>
```

### Q4: 想看详细的使用说明

**解决**：
阅读 `README.md`

---

## 🚀 下一步

1. ✅ 运行基线模型，看看准确率
2. ✅ 收集更多数据（500+ 个样本）
3. ✅ 重新训练，对比性能
4. ✅ 尝试不同算法
5. ✅ 写实验报告

---

**祝实验成功！** 🎉
